import firebase_admin
from firebase_admin import credentials, firestore
import os
import json
import pandas as pd

from dotenv import load_dotenv
load_dotenv()

def get_firebase_credentials_from_env():
    """å¾ç’°å¢ƒè®Šæ•¸è®€å– Firebase æœå‹™å¸³è™Ÿé‡‘é‘°ã€‚"""
    firebase_credentials = os.getenv("FIREBASE_CREDENTIALS")
    if not firebase_credentials:
        raise ValueError("FIREBASE_CREDENTIALS ç’°å¢ƒè®Šæ•¸æœªè¨­å®šã€‚")
    try:
        service_account_info = json.loads(firebase_credentials)
        return credentials.Certificate(service_account_info)
    except json.JSONDecodeError:
        raise ValueError("FIREBASE_CREDENTIALS ç’°å¢ƒè®Šæ•¸æ ¼å¼éŒ¯èª¤ã€‚")

# åˆå§‹åŒ– Firebase
try:
    if not firebase_admin._apps:
        firebase_cred = get_firebase_credentials_from_env()
        firebase_admin.initialize_app(firebase_cred)
    db = firestore.client()
    print("âœ… æˆåŠŸé€£æ¥ Firebase")
except Exception as e:
    print(f"âŒ Firebase é€£æ¥å¤±æ•—: {e}")
    exit()

def download_and_preprocess_data():
    """
    å¾ Firebase ä¸‹è¼‰æ‰€æœ‰å¯¦é©—çš„å°è©±è³‡æ–™ï¼Œä¸¦è½‰æ›ç‚ºä¸€å€‹ Pandas DataFrameã€‚
    """
    all_messages = []
    
    experiments_ref = db.collection("experiments")
    experiments_docs = experiments_ref.stream()

    for exp_doc in experiments_docs:
        exp_data = exp_doc.to_dict()
        experiment_id = exp_doc.id
        bot_role = exp_data.get("bot_role", "æœªçŸ¥")

        print(f"è™•ç†å¯¦é©— ID: {experiment_id}ï¼Œæ©Ÿå™¨äººè§’è‰²: {bot_role}")
        
        messages_ref = db.collection("experiments").document(experiment_id).collection("messages")
        messages_docs = messages_ref.order_by("timestamp").stream()

        for msg_doc in messages_docs:
            msg_data = msg_doc.to_dict()
            msg_data['experiment_id'] = experiment_id
            msg_data['bot_role'] = bot_role
            all_messages.append(msg_data)

    if not all_messages:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å°è©±è³‡æ–™ã€‚")
        return pd.DataFrame()

    df = pd.DataFrame(all_messages)
    
    # è³‡æ–™æ¸…ç†èˆ‡å‹æ…‹è½‰æ›
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    # å»ºç«‹ä¸€å€‹æ¨™ç¤ºèª°ç™¼è¨€çš„æ¬„ä½
    # å¦‚æœ user_id æ˜¯ 'ä¸ä»‹å…¥AI'ã€'è³‡è¨Šæä¾›è€…AI' ç­‰ï¼Œå‰‡è¦–ç‚º AI ç™¼è¨€
    # ğŸ’¡ æ ¹æ“šæ‚¨çš„ç¨‹å¼ç¢¼ï¼ŒAI ç™¼è¨€çš„ user_id æœƒæ˜¯å®ƒçš„è§’è‰²åç¨±ã€‚
    ai_roles = ['æ•´åˆå‹AI', 'æ··åˆå‹AI', 'æ¢ç©¶å‹AI', 'ç„¡ä»‹å…¥AI'] # è«‹æ ¹æ“šæ‚¨çš„å¯¦éš›è§’è‰²åç¨±èª¿æ•´
    df['speaker_type'] = df.apply(
        lambda row: 'ai' if row['user_id'] in ai_roles or row['from'] == 'assistant' else 'user',
        axis=1
    )
    
    print("âœ… è³‡æ–™ä¸‹è¼‰ä¸¦è½‰æ›å®Œæˆï¼")
    return df

# åŸ·è¡Œå‡½å¼
df = download_and_preprocess_data()
if not df.empty:
    print("\nDataFrame ç¯„ä¾‹ï¼š")
    print(df.head())
    print("\nè³‡æ–™æ¬„ä½ï¼š", df.columns)
    
    # å°‡ DataFrame å­˜æˆ CSV æª”ï¼Œæ–¹ä¾¿å¾ŒçºŒåˆ†æ
    df.to_csv("conversation_data.csv", index=False, encoding='utf-8-sig')
    print("\nâœ… è³‡æ–™å·²å„²å­˜ç‚º conversation_data.csv")



# # è¨ˆç®—å„æˆå“¡çš„å…±åŒè³‡è¨Šèˆ‡ç§æœ‰è³‡è¨Šæ•¸é‡
# information_counts = df.groupby(['user_id', 'information_type']).size().unstack(fill_value=0)
# print("\nè³‡è¨Šæ­éœ²æ•¸é‡çµ±è¨ˆï¼š")
# print(information_counts)
